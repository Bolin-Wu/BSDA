\documentclass[10pt,handout]{beamer}
%\documentclass[10pt]{beamer}
\usepackage[english]{babel} % Anpassa efter svenska. Ger svensk logga.
\usepackage[utf8]{inputenc} % Anpassa efter linux
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
%\input{../common/lststan} % Stan listing
\usepackage{lstbayes}
\usepackage[all,poly,ps,color]{xy}


\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage{../common/beamerthemeUppsala}
%\usetheme{Uppsala}
%\usecolortheme{UU} % Anpassa efter UU:s frger och logga
%\hypersetup{pdfpagemode=FullScreen} % Adobe Reader ska ppna fullskrm
\setbeamertemplate{itemize items}[circle]

% \usepackage{beamerthemesplit}
\usepackage{amsmath,amsfonts,amssymb}
% \usepackage{amssymb}
% \usepackage{graphics}
% \usepackage{graphicx}
% \usepackage{epsfig}
% \usepackage[latin1]{inputenc}
 \usepackage{color}
% \usepackage{fancybox}
% \usepackage{psfrag}
% \usepackage[english]{babel}
 \setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber}

% Input new commands
\input{../common/commands.tex}

\def\dashxy(#1){%
  /xydash{[#1] 0 setdash}def}
\def\grayxy(#1){%
  /xycolor{#1 setgray}def}
\newgraphescape{D}[1]{!{\ar @*{[!\dashxy(2 2)]} "#1"}}
\newgraphescape{P}[1]{!{\ar "#1"}}
\newgraphescape{F}[1]{!{*+=<2em>[F=]{#1}="#1"}}
\newgraphescape{O}[1]{!{*+=<2em>[F]{#1}="#1"}}
\newgraphescape{V}[1]{!{*+=<2em>[o][F]{#1}="#1"}}
\newgraphescape{B}[3]{!{{ "#1"*+#3\frm{} }.{ "#2"*+#3\frm{} } *+[F:!\grayxy(0.75)]\frm{}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setlength{\parskip}{3mm}
\title[]{{\color{black}Bayesian Statistics and Data Analysis \\ Lecture 7}}
\author[]{M{\aa}ns Magnusson \\ Department of Statistics, Uppsala University \\ Thanks to Aki Vehtari, Aalto University}
\date{}

\begin{document}

\frame{\titlepage
% \thispagestyle{empty}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
\frame{\sectionpage}



 \begin{frame}

\frametitle{Model checking -- overview}

  \begin{itemize}
  \item<+-> Sensibility with respect to additional information not used in modeling
    \begin{itemize}
    \item e.g., if posterior would claim that hazardous chemical
      decreases probability of death
    \end{itemize}
  \item<+-> External validation
    \begin{itemize}
    \item compare predictions to completely new observations
    \item cf. relativity theory predictions
    \end{itemize}
  \item<+-> Internal validation
    \begin{itemize}
    \item posterior predictive checking
    \item cross-validation predictive checking
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Newcomb's speed of light measurements
    \begin{itemize}
    \item model $y\sim\N(\mu,\sigma)$ with prior $(\mu,\log\sigma)\propto 1$
    \end{itemize}
  \item<2-> Posterior predictive replicate $y^{\rm rep}$
    \begin{itemize}
    \item<3-> draw $\mu^{(s)},\sigma^{(s)}$ from the posterior $p(\mu,\sigma|y)$
    \item<4-> draw $y^{\mathrm{rep}\,(s)}$ from $\N(\mu^{(s)},\sigma^{(s)})$
    \item<5-> repeat $n$ times to get $y^{\mathrm{rep}}$ with $n$ replicates\\~\\
    \uncover<6->{\includegraphics[width=7cm]{figs/light_ppc_1hist.pdf}}
      \end{itemize}
    \end{itemize}

\end{frame}

\begin{frame}

\frametitle{Replicates vs. future observation}

  \begin{itemize}
  \item Predictive $\tilde{y}$ is the next not yet observed possible
    observation. $y^{\mathrm{rep}}$ refers to replicating the whole
    experiment (potentially with same values of $x$) and obtaining as
    many replicated observations as in the original data.
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Generate several replicated datasets $y^{\rm rep}$
  \item<2-> Compare to the original dataset
  \end{itemize}
  \vspace{-1\baselineskip}
  \uncover<3->{\includegraphics[width=11.5cm]{figs/light_ppc_10hist.pdf}}

\end{frame}


\begin{frame}

\frametitle{Posterior predictive checking with test statistic}

  \begin{itemize}
  \item Replicated data sets $y^{\rep}$
  \item Test quantity (or discrepancy measure) $T(y,\theta)$
    \begin{itemize}
    \item summary quantity for the observed data $T(y,\theta)$
    \item summary quantity for a replicated data $T(y^{\rep},\theta)$
    \item can be easier to compare summary quantities than data sets
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Compute test statistic for data $T(y,\theta)=\min(y)$
  \item<2-> Compute test statistic $\min(y^{\rm rep})$ for many replicated datasets
  \end{itemize}
  \vspace{-1.5\baselineskip}
  \uncover<3->{\includegraphics[width=11cm]{figs/light_ppc_min.pdf}}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking -- example}

  \begin{itemize}
  \item<1-> Good test statistic is ancillary (or almost)
    \begin{itemize}
    \item ancillary if it depends only on observed data and if its
      distribution is independent of the parameters of the model
    \end{itemize}
  \item<2-> Bad test statistic is highly dependent of the parameters
    \begin{itemize}
    \item e.g. variance for normal model
    \end{itemize}
  \end{itemize}
  \vspace{-1.5\baselineskip}
  \uncover<3->{\includegraphics[width=10cm]{figs/light_ppc_var.pdf}}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking}

  \begin{itemize}
    \only<4->{\color{gray}}
  \item<1-> \textit{Posterior predictive $p$-value}
    \begin{eqnarray*}
      p & = & \Pr(T(y^{\rep},\theta)\geq T(y,\theta)|y)\\
      & = & \int\int
      I_{T(y^{\rep},\theta)\geq T(y,\theta)}p(y^{\rep}|\theta)p(\theta|y)dy^{\rep}d\theta
    \end{eqnarray*}
    where $I$ is an indicator function
    \begin{itemize}
    \item<2-> \only<4->{\color{gray}} having $(y^{\rep\,(s)},\theta^{(s)})$ from the posterior predictive
      distribution, easy to compute
      \begin{equation*}
        T(y^{\rep (s)},\theta^{(s)})\geq T(y,\theta^{(s)}), \quad s=1,\ldots,S
      \end{equation*}
    \end{itemize}
    \vspace{-1.5\baselineskip}
  \item<3-> Posterior predictive $p$-value (ppp-value) estimated whether
    difference between the model and data could arise by chance
  \item<4-> \color{black} Not commonly used, since the distribution of test
    statistic has more information
  \end{itemize}

\end{frame}


% \begin{frame}

% \frametitle{Calibration of ppp-values}

%   \begin{itemize}
%   \item In the special case that the parameters $\theta$ are known (or
%     estimated to a very high precision) or in which the test statistic
%     $T(y)$ is ancillary (that is,
%     if it depends only on observed data and if its distribution is
%     independent of the parameters of the model) with a continuous
%     distribution, the posterior predictive $p$-value
%     $\Pr(T(y^{\rep})\!>\!T(y)|y)$ has a distribution that is uniform
%     if the model is true.
%   \item Under these conditions, $p$-values less than 0.1 occur 10\% of
%     the time, $p$-values less than 0.05 occur 5\% of the time, and so
%     forth.
%   \end{itemize}

% \end{frame}

\begin{frame}[fragile]

\frametitle{Marginal and CV predictive checking}

  \begin{itemize}
  \item Consider marginal predictive distributions $p(\tilde{y}_i|y)$
    and each observation separately
    \begin{itemize}
    \item marginal posterior p-values
      \begin{align*}
        p_i = \mbox{Pr}(T(y_i^{\rep}) \leq T(y_i) | y)
      \end{align*}
      if $T(y_i)=y_i$
      \begin{align*}
        p_i = \mbox{Pr}(y_i^{\rep} \leq y_i | y)
      \end{align*}
    \end{itemize}
  \item<2-> if $Pr(\tilde{y}_i|y)$ well calibrated, distribution of $p_i$
    would be uniform between 0 and 1
    \begin{itemize}
    \item holds better for cross-validation predictive tests
      (cross-validation Ch 7)
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}[fragile]

\frametitle{Marginal predictive checking - Example}

  \begin{itemize}
  \item Marginal tail area or Probability integral transform (PIT)
    \begin{align*}
      p_i = p(y_i^{\rep} \leq y_i | y)
    \end{align*}
  \item if $p(\tilde{y}_i|y)$ is well calibrated, distribution of $p_i$'s
    would be uniform between 0 and 1
  \end{itemize}
  \vspace{-1.5\baselineskip}
  \uncover<2->{\includegraphics[width=10cm]{figs/light_ppc_pit.pdf}}

\end{frame}

\begin{frame}

\frametitle{Sensitivity analysis}

  \begin{itemize}
  \item How much different choices in model structure and priors affect the results
    \begin{itemize}
      \item<2-> test different models and priors
      \item<3-> alternatively combine different models to one model
        \begin{itemize}
        \item e.g. hierarchical model instead of separate and pooled
        \item e.g. $t$ distribution contains Gaussian as a special case
      \end{itemize}
      \item<3-> robust models are good for testing sensitivity to ``outliers''
        \begin{itemize}
        \item e.g. $t$ instead of Gaussian
        \end{itemize}
    \end{itemize}
    \item<4-> Compare sensitivity of essential inference quantities
      \begin{itemize}
      \item extreme quantiles are more sensitive than means and medians
      \item extrapolation is more sensitive than interpolation
      \end{itemize}
    \end{itemize}

\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  \begin{itemize}
  \item Example from Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael
    Betancourt, and Andrew Gelman (2019). Visualization in Bayesian
    workflow. \url{https://doi.org/10.1111/rssa.12378}
  \item Estimation of human exposure to air pollution from particulate
    matter measuring less than 2.5 microns in diameter ($\mathrm{PM}_{2.5}$)
    \begin{itemize}
    \item Exposure to $\mathrm{PM}_{2.5}$ is linked to a number of
      poor health outcomes and a recent report estimated that
      $\mathrm{PM}_{2.5}$ is responsible for three million deaths
      worldwide each year (Shaddick et al., 2017)
    \item In order to estimate the public health effect of ambient
      $\mathrm{PM}_{2.5}$, we need a good estimate of the
      $\mathrm{PM}_{2.5}$ concentration at the same spatial resolution
      as our population estimates.
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  \begin{itemize}
  \item Direct measurements of PM 2.5 from ground monitors at 2980
    locations
  \item High-resolution satellite data of aerosol optical depth
  \end{itemize}
  \begin{center}
    \only<1>{\vspace{-1.8\baselineskip}\includegraphics[height=7cm]{figs/map-data.png}}
    \only<2>{\vspace{-1.8\baselineskip}\includegraphics[height=7cm]{figs/plot1.png}}
    \only<3>{\hspace{-3cm}\includegraphics[height=6.55cm]{figs/plot2.png}}
\end{center}
\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  Prior predictive checking

  \begin{center}
    \only<1>{\includegraphics[width=11cm]{figs/pm25_pp1a.pdf}}
    \only<2>{\includegraphics[width=11cm]{figs/pm25_pp1b.pdf}}
    \only<3>{\includegraphics[width=11cm]{figs/pm25_pp2.pdf}}
\end{center}
\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}

  Posterior predictive checking -- marginal predictive distributions
\begin{figure}
\centering
\begin{subfigure}{0.48\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_dens1.png}
\caption{Model 1}
\end{subfigure}
~
\begin{subfigure}{0.48\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_dens2.png}
\caption{Model 2}
\end{subfigure}
% ~
% \begin{subfigure}{0.31\textwidth}
% \includegraphics[width=\textwidth]{ppc_dens3.png}
% \caption{Model 3}
% \end{subfigure}
\end{figure}

\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}


  Posterior predictive checking -- test statistic (skewness)
\begin{figure}
\centering
\begin{subfigure}{0.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_skew1.png}
\caption{Model 1}
\end{subfigure}
~
\begin{subfigure}{0.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_skew2.png}
\caption{Model 2}
\end{subfigure}
~
\begin{subfigure}{0.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_skew3.png}
\caption{Model 3}
\end{subfigure}

\end{figure}

\end{frame}

\begin{frame}

\frametitle{Example: Exposure to air pollution}


  Posterior predictive checking -- test statistic (median for groups)

  \begin{figure}
\centering
\begin{subfigure}{.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_med_grouped1.png}
\caption{Model 1}
\end{subfigure}
~
\begin{subfigure}{.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_med_grouped2.png}
\caption{Model 2}
\end{subfigure}
~
\begin{subfigure}{.31\textwidth}
\includegraphics[width=\textwidth]{figs/ppc_med_grouped3.png}
\caption{Model 3}
\end{subfigure}

\end{figure}

\end{frame}



\begin{frame}

\frametitle{Example: Exposure to air pollution}


  LOO predictive checking -- LOO-PIT

\includegraphics[width=\textwidth]{figs/ppc_loo_pit_corrected_pm25.png}



\vspace{2\baselineskip}
{\scriptsize EDIT 2020: These plots use boundary corrected KDE which is a better choice than the non-boundary corrected KDE used in the plots in the
paper.}

\end{frame}

\begin{frame}[fragile]

\frametitle{Example of posterior predictive checking}

    \includegraphics[width=11cm]{figs/mesquite_ppc.pdf}\\
  \vspace{-0.1\baselineskip} {Predicting the yields of mesquite bushes.\\
    \color{gray} \footnotesize
    Gelman, Hill \& Vehtari (2020): Regression and Other Stories, Chapter 11.}\\

\end{frame}

\begin{frame}[fragile]

\frametitle{Example of posterior predictive checking}

  Diabetes prediction with logistic regression -
  \href{https://avehtari.github.io/modelselection/diabetes.html}{diabetes demo}

     \only<1>{\vspace{-.6\baselineskip}\includegraphics[width=8.5cm]{figs/diabetes_corrplot.pdf}}
     \only<2>{PPC with binning for binary data\\ \includegraphics[width=11cm]{figs/diabetes_calibration_binned.pdf}}
     \only<3>{PPC with non-linear regression for binary data\\ \includegraphics[width=11cm]{figs/diabetes_calibration_regression.pdf}}

\end{frame}

\begin{frame}[fragile]

\frametitle{Posterior predictive checking}

  \vspace{-0.2\parskip}
  \begin{itemize}
  \item demo demos\_rstan/ppc/poisson-ppc.Rmd
  \end{itemize}

  \vspace{-0.2\parskip}
  {\color{gray}\footnotesize
\begin{lstlisting}[language=Stan]
data {
  int<lower=1> N;
  int<lower=0> y[N];
}
parameters {
  real<lower=0> lambda;
}
model {
  lambda ~ exponential(0.2);
  y ~ poisson(lambda);
}
\end{lstlisting}
  }
  \vspace{-\parskip}
  {\footnotesize
\begin{lstlisting}[language=Stan]
generated quantities {
  real log_lik[N];
  int y_rep[N];
  for (n in 1:N) {
    y_rep[n] = poisson_rng(lambda);
    log_lik[n] = poisson_lpmf(y[n] | lambda);
    }
}
\end{lstlisting}
 }
\end{frame}


\begin{frame}

\frametitle{Further reading and examples}

  \begin{itemize}
  \item Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael
    Betancourt, and Andrew Gelman (2019). Visualization in Bayesian
    workflow. \url{https://doi.org/10.1111/rssa.12378}.
  \item Graphical posterior predictive checks using the bayesplot package
    \url{http://mc-stan.org/bayesplot/articles/graphical-ppcs.html}
  \item Another demo \href{http://avehtari.github.io/BDA_R_demos/demos_rstan/ppc/poisson-ppc.html}{demos\_rstan/ppc/poisson-ppc.Rmd}
  \item Michael Betancourt's workflow case study with prior and posterior predictive checking
    \begin{itemize}
    \item for RStan \url{https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html}
    \item for PyStan \url{https://github.com/betanalpha/jupyter_case_studies/blob/master/principled_bayesian_workflow/principled_bayesian_workflow.ipynb}
    \end{itemize}
  \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
